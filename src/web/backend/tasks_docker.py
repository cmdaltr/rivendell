"""
Celery Tasks - Dockerized Version

Background tasks for running Elrond analysis in Docker containers.
This version runs Elrond directly in the same container environment.
"""

import subprocess
import sys
import os
import re
import json
import time
import hashlib
from datetime import datetime
from pathlib import Path

from celery import Celery
from celery.utils.log import get_task_logger
import redis

from config import settings
from storage import JobStorage
from models.job import JobStatus, PendingAction

# Initialize Celery
celery_app = Celery(
    "elrond",
    broker=settings.celery_broker_url,
    backend=settings.celery_result_backend,
)

logger = get_task_logger(__name__)
job_storage = JobStorage()

# Redis client for image locking
_redis_client = None


def get_redis_client():
    """Get or create Redis client for image locking."""
    global _redis_client
    if _redis_client is None:
        redis_host = os.environ.get("REDIS_HOST", "redis")
        redis_port = int(os.environ.get("REDIS_PORT", 6379))
        _redis_client = redis.Redis(host=redis_host, port=redis_port, db=1)  # Use db=1 for locks
    return _redis_client


def _get_image_lock_key(image_path: str) -> str:
    """Generate a Redis key for an image lock."""
    # Normalize the path and create a hash for consistent key naming
    normalized = os.path.normpath(image_path).lower()
    path_hash = hashlib.md5(normalized.encode()).hexdigest()[:16]
    return f"rivendell:image_lock:{path_hash}"


def acquire_image_locks(job_id: str, image_paths: list, timeout: int = 3600, retry_interval: int = 10) -> bool:
    """
    Acquire locks on all image paths. Waits if any image is in use.

    Args:
        job_id: Job ID (used as lock value for identification)
        image_paths: List of image paths to lock
        timeout: Lock timeout in seconds (default 1 hour)
        retry_interval: Seconds between retry attempts

    Returns:
        True if all locks acquired, False if failed
    """
    redis_client = get_redis_client()
    acquired_locks = []

    try:
        for image_path in image_paths:
            lock_key = _get_image_lock_key(image_path)
            image_name = os.path.basename(image_path)

            while True:
                # Try to acquire the lock using SETNX (set if not exists)
                # The lock value contains job_id for debugging
                lock_acquired = redis_client.set(
                    lock_key,
                    f"{job_id}:{datetime.now().isoformat()}",
                    nx=True,  # Only set if not exists
                    ex=timeout  # Expire after timeout
                )

                if lock_acquired:
                    acquired_locks.append(lock_key)
                    logger.info(f"Job {job_id}: Acquired lock on '{image_name}'")
                    break
                else:
                    # Lock exists - another job is using this image
                    existing_lock = redis_client.get(lock_key)
                    if existing_lock:
                        existing_job = existing_lock.decode().split(":")[0]
                        logger.info(f"Job {job_id}: Waiting for '{image_name}' (in use by job {existing_job})")

                        # Update job status to show waiting
                        job = job_storage.get_job(job_id)
                        if job:
                            job.log.append(
                                f"[{datetime.now().isoformat().replace('T', ' ')}] -> Waiting for '{image_name}' (in use by another job)"
                            )
                            job_storage.save_job(job)

                    # Wait and retry
                    time.sleep(retry_interval)

                    # Check if our job was cancelled while waiting
                    job = job_storage.get_job(job_id)
                    if job and job.status == JobStatus.CANCELLED:
                        logger.info(f"Job {job_id}: Cancelled while waiting for image lock")
                        release_image_locks(acquired_locks)
                        return False

        return True

    except Exception as e:
        logger.error(f"Job {job_id}: Error acquiring image locks: {e}")
        # Release any locks we acquired
        release_image_locks(acquired_locks)
        return False


def release_image_locks(lock_keys: list):
    """Release image locks."""
    if not lock_keys:
        return

    redis_client = get_redis_client()
    for lock_key in lock_keys:
        try:
            redis_client.delete(lock_key)
            logger.debug(f"Released lock: {lock_key}")
        except Exception as e:
            logger.warning(f"Error releasing lock {lock_key}: {e}")


def release_image_locks_for_job(job_id: str, source_paths: list):
    """
    Release image locks held by a specific job.
    Only releases locks if they are actually held by this job.
    """
    if not source_paths:
        return

    redis_client = get_redis_client()
    for image_path in source_paths:
        lock_key = _get_image_lock_key(image_path)
        try:
            # Check if this job holds the lock
            lock_value = redis_client.get(lock_key)
            if lock_value:
                lock_str = lock_value.decode() if isinstance(lock_value, bytes) else str(lock_value)
                if lock_str.startswith(f"{job_id}:"):
                    redis_client.delete(lock_key)
                    logger.info(f"Released image lock for job {job_id}: {os.path.basename(image_path)}")
        except Exception as e:
            logger.warning(f"Error releasing lock for {image_path}: {e}")


def _request_sudo_confirmation(job, target_path: str, reason: str):
    """Set job to awaiting confirmation status for sudo directory removal."""
    from models.job import PendingAction

    job.status = JobStatus.AWAITING_CONFIRMATION
    job.pending_action = PendingAction(
        action_type="sudo_remove_directory",
        target_path=target_path,
        message=f"Failed to remove directory: {reason}. Use sudo to force removal?"
    )
    job_storage.save_job(job)
    logger.info(f"Job {job.id} awaiting sudo confirmation for: {target_path}")


def confirm_sudo_action(job_id: str) -> bool:
    """
    Execute the pending sudo action for a job.
    Returns True if successful, False otherwise.
    """
    job = job_storage.get_job(job_id)
    if not job or job.status != JobStatus.AWAITING_CONFIRMATION:
        return False

    if not job.pending_action or job.pending_action.action_type != "sudo_remove_directory":
        return False

    target_path = job.pending_action.target_path

    job.log.append(
        f"[{datetime.now().isoformat().replace('T', ' ')}] -> User confirmed sudo removal of: {target_path}"
    )
    job_storage.save_job(job)

    try:
        # Use rm -rf (container runs as root, no sudo needed)
        result = subprocess.run(
            ["rm", "-rf", target_path],
            capture_output=True,
            timeout=300  # 5 minute timeout
        )

        if result.returncode == 0:
            job.log.append(
                f"[{datetime.now().isoformat().replace('T', ' ')}] -> Successfully removed directory"
            )
            job.status = JobStatus.PENDING  # Reset to pending so it can be restarted
            job.pending_action = None
            job_storage.save_job(job)
            return True
        else:
            stderr = result.stderr.decode() if result.stderr else "Unknown error"
            job.log.append(
                f"[{datetime.now().isoformat().replace('T', ' ')}] -> Removal failed: {stderr}"
            )
            job.status = JobStatus.FAILED
            job.error = f"Directory removal failed: {stderr}"
            job.pending_action = None
            job.completed_at = datetime.now()
            job_storage.save_job(job)
            return False

    except subprocess.TimeoutExpired:
        job.log.append(
            f"[{datetime.now().isoformat().replace('T', ' ')}] -> Directory removal timed out"
        )
        job.status = JobStatus.FAILED
        job.error = "Directory removal timed out after 5 minutes"
        job.pending_action = None
        job.completed_at = datetime.now()
        job_storage.save_job(job)
        return False
    except Exception as e:
        job.log.append(
            f"[{datetime.now().isoformat().replace('T', ' ')}] -> Directory removal error: {e}"
        )
        job.status = JobStatus.FAILED
        job.error = f"Directory removal error: {e}"
        job.pending_action = None
        job.completed_at = datetime.now()
        job_storage.save_job(job)
        return False


def cancel_sudo_action(job_id: str) -> bool:
    """Cancel the pending sudo action and fail the job."""
    job = job_storage.get_job(job_id)
    if not job or job.status != JobStatus.AWAITING_CONFIRMATION:
        return False

    job.log.append(
        f"[{datetime.now().isoformat().replace('T', ' ')}] -> User cancelled sudo removal"
    )
    job.status = JobStatus.FAILED
    job.error = "Directory removal cancelled by user"
    job.pending_action = None
    job.completed_at = datetime.now()
    job_storage.save_job(job)
    return True


def translate_path_for_worker(path_str: str) -> str:
    """
    Translate paths from backend container perspective to celery-worker perspective.

    Both containers mount:
      - elrond_uploads volume -> /tmp/elrond/uploads (SAME in both containers)
      - /tmp/rivendell (host) -> /tmp/elrond/output (worker) or /host/tmp/rivendell (backend)

    Args:
        path_str: Path from backend perspective

    Returns:
        Path translated for celery worker
    """
    path_str = str(path_str)

    # Paths in /tmp/elrond/uploads are the SAME in both containers (shared volume)
    if path_str.startswith("/tmp/elrond/uploads/"):
        return path_str

    # Backend uses /host/tmp/rivendell for output, worker uses /tmp/elrond/output
    if path_str.startswith("/host/tmp/rivendell"):
        return path_str.replace("/host/tmp/rivendell", "/tmp/elrond/output")

    # Backend uses /tmp/elrond/output, worker uses same
    if path_str.startswith("/tmp/elrond/output"):
        return path_str

    # Default: return as-is
    return path_str


def _resolve_destination(job) -> Path:
    """
    Resolve the destination directory using the same logic as job creation.
    Uses case number as the output directory name instead of image name.
    """
    if job.destination_path:
        return Path(job.destination_path)

    if job.source_paths:
        first_source = Path(job.source_paths[0])
        if first_source.is_file():
            # Use case number instead of image name for output directory
            return first_source.parent / job.case_number
        return first_source / job.case_number

    return Path(settings.output_dir) / job.case_number


@celery_app.task(bind=True)
def start_analysis(self, job_id: str):
    """
    Start Elrond analysis task in dockerized environment.

    Runs the full forensics engine directly in the container.
    Uses Redis-based locking to ensure only one job can process a given image at a time.

    Args:
        job_id: Job ID
    """
    job = job_storage.get_job(job_id)

    if not job:
        logger.error(f"Job {job_id} not found")
        return

    # Track acquired locks for cleanup
    acquired_lock_keys = []

    try:
        # Acquire locks on all source images before starting
        # This ensures jobs using the same image wait for each other
        if job.source_paths:
            job.log.append(f"[{datetime.now().isoformat().replace('T', ' ')}] -> Checking image availability...")
            job_storage.save_job(job)

            # Build list of lock keys we need to acquire
            for image_path in job.source_paths:
                acquired_lock_keys.append(_get_image_lock_key(image_path))

            # Try to acquire all locks (will wait if images are in use)
            if not acquire_image_locks(job_id, job.source_paths, timeout=7200, retry_interval=10):
                # Failed to acquire locks (job was cancelled while waiting)
                job.status = JobStatus.CANCELLED
                job.log.append(f"[{datetime.now().isoformat().replace('T', ' ')}] -> Job cancelled while waiting for images")
                job.completed_at = datetime.now()
                job_storage.save_job(job)
                return

        # Update job status
        job.status = JobStatus.RUNNING
        job.started_at = datetime.now()
        job.log.append(f"[{datetime.now().isoformat().replace('T', ' ')}] -> Starting rivendell...")
        job_storage.save_job(job)

        # Build elrond command
        cmd = build_elrond_command(job)

        logger.info(f"Running command: {' '.join(cmd)}")

        # Set destination directory - must translate to worker perspective
        dest_dir_backend = _resolve_destination(job)
        dest_dir_str = translate_path_for_worker(str(dest_dir_backend))
        dest_dir = Path(dest_dir_str)

        # Check if force_overwrite is set and directory exists
        if getattr(job.options, "force_overwrite", False):
            if dest_dir.exists():
                import shutil

                logger.info(f"Force overwrite enabled, removing existing directory: {dest_dir_str}")

                job.log.append(
                    f"[{datetime.now().isoformat().replace('T', ' ')}] -> Removing existing directory: {dest_dir_str} - stand by..."
                )
                job_storage.save_job(job)

                # Use rm -rf with progress monitoring for large directories
                start_time = datetime.now()
                try:
                    import time

                    # Start rm -rf in background
                    rm_process = subprocess.Popen(
                        ["rm", "-rf", dest_dir_str],
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL,
                    )

                    # Monitor with periodic updates every 10 seconds
                    last_update = datetime.now()
                    while rm_process.poll() is None:
                        time.sleep(1)
                        elapsed = (datetime.now() - start_time).total_seconds()

                        # Update every 10 seconds
                        if (datetime.now() - last_update).total_seconds() >= 10:
                            job.log.append(
                                f"[{datetime.now().isoformat().replace('T', ' ')}] -> Still removing directory... ({int(elapsed)}s elapsed)"
                            )
                            job_storage.save_job(job)
                            last_update = datetime.now()

                        # Timeout after 5 minutes
                        if elapsed > 300:
                            rm_process.kill()
                            raise subprocess.TimeoutExpired(
                                cmd=["rm", "-rf", dest_dir_str], timeout=300
                            )

                    # Check exit code
                    if rm_process.returncode != 0:
                        raise subprocess.CalledProcessError(
                            rm_process.returncode, ["rm", "-rf", dest_dir_str]
                        )

                    elapsed = (datetime.now() - start_time).total_seconds()
                    logger.info(f"Successfully removed directory: {dest_dir_str} in {elapsed:.1f}s")
                    job.log.append(
                        f"[{datetime.now().isoformat().replace('T', ' ')}] -> Successfully removed directory in {elapsed:.1f}s"
                    )
                except subprocess.TimeoutExpired:
                    logger.error(f"Timeout removing directory: {dest_dir_str}")
                    job.log.append(
                        f"[{datetime.now().isoformat().replace('T', ' ')}] -> Timeout removing directory - requesting sudo confirmation"
                    )
                    _request_sudo_confirmation(job, dest_dir_str, "Timeout after 5 minutes")
                    return
                except subprocess.CalledProcessError as e:
                    logger.error(f"Error removing directory (exit code {e.returncode})")
                    job.log.append(f"[{datetime.now().isoformat().replace('T', ' ')}] -> Error removing directory - requesting sudo confirmation")
                    _request_sudo_confirmation(job, dest_dir_str, f"Permission denied (exit code {e.returncode})")
                    return
                except Exception as e:
                    logger.error(f"Error removing directory: {e}")
                    job.log.append(
                        f"[{datetime.now().isoformat().replace('T', ' ')}] -> Error removing directory - requesting sudo confirmation"
                    )
                    _request_sudo_confirmation(job, dest_dir_str, str(e))
                    return
                job_storage.save_job(job)

        # Create the output directory if it doesn't exist
        dest_dir.mkdir(parents=True, exist_ok=True)

        # Run elrond directly in container
        # Since we're already in the forensics container, we can run it directly
        elrond_path = os.environ.get("ELROND_HOME", "/opt/elrond")
        elrond_script = Path(elrond_path) / "elrond.py"

        if not elrond_script.exists():
            # Elrond not installed - create placeholder error
            raise FileNotFoundError(
                f"Elrond script not found at {elrond_script}. "
                f"Please install Elrond or set ELROND_HOME environment variable to point to Elrond installation."
            )

        # Prepend python3 and elrond script path to command
        cmd.insert(0, str(elrond_script))
        cmd.insert(0, "python3")

        logger.info(f"Executing: {' '.join(cmd)}")

        # Run elrond with proper environment
        env = os.environ.copy()
        env["PYTHONPATH"] = f"{elrond_path}:{env.get('PYTHONPATH', '')}"
        env["ELROND_HOME"] = elrond_path
        env["ELROND_OUTPUT"] = str(settings.output_dir)
        env["ELROND_NONINTERACTIVE"] = "1"  # Signal non-interactive mode
        env["PYTHONUNBUFFERED"] = "1"  # Disable Python output buffering for real-time logs

        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1,  # Line buffering to get output in real-time
            cwd=dest_dir_str,
            env=env,
        )

        # Monitor progress
        progress_count = 0
        last_log_message = None  # Track last message for deduplication
        seen_phases = set()  # Track seen phase transitions to prevent duplicates
        seen_filepaths = set()  # Track seen filepaths to prevent duplicates

        # Phase-based progress tracking
        # Rivendell processes ALL images through each phase before moving to the next:
        # 1. Identification (mount all): 0-15%
        # 2. Collection (all images): 15-35%
        # 3. Processing (all artefacts): 35-70%
        # 4. Analysis: 70-95%
        total_images = max(1, len(job.source_paths))
        current_phase = "identification"  # Track current phase
        images_collected = 0  # Track how many images have completed collection
        images_processed = 0  # Track how many images have completed processing

        # Counter for repeated patterns (like IE index.dat)
        ie_indexdat_count = 0
        ie_indexdat_logged = False

        # Verbose logging - write all output to verbose.log when debug is enabled
        debug_enabled = getattr(job.options, "debug", False)
        verbose_log_file = None
        if debug_enabled:
            verbose_log_path = os.path.join(dest_dir_str, "verbose.log")
            try:
                verbose_log_file = open(verbose_log_path, "w")
                logger.info(f"Verbose logging enabled, writing to: {verbose_log_path}")
            except Exception as e:
                logger.warning(f"Failed to open verbose log file: {e}")

        # Track phase completion for validation
        phases_completed = {
            "collection": False,
            "processing": False,
            "analysis": False,
        }
        analysis_phase_started = False

        for line in iter(process.stdout.readline, ""):
            line = line.strip()
            if line:
                # Strip ANSI color codes
                line = re.sub(r"\x1b\[[0-9;]*m", "", line)

                # Write ALL output to verbose.log when debug is enabled (before any filtering)
                if verbose_log_file:
                    try:
                        verbose_log_file.write(line + "\n")
                        verbose_log_file.flush()
                    except Exception:
                        pass

                # Exclude verbose messages (MITRE enrichment, verbose command output) unless debug is enabled
                if not debug_enabled:
                    excluded_keywords = ["mitre", "extracting mitre", "mitre enrichment"]
                    excluded_patterns = [
                        r"-> Command:",  # Exclude verbose command line output
                    ]
                    has_excluded = any(kw in line.lower() for kw in excluded_keywords)
                    # Check excluded patterns
                    if not has_excluded:
                        for pattern in excluded_patterns:
                            if re.search(pattern, line, re.IGNORECASE):
                                has_excluded = True
                                break
                    if has_excluded:
                        continue

                # Special handling for IE index.dat messages - aggregate into count
                if re.search(r"processing (small|large) IE index\.dat", line, re.IGNORECASE):
                    ie_indexdat_count += 1
                    if not ie_indexdat_logged:
                        # Log the first one with a placeholder for count
                        ie_indexdat_logged = True
                        line = f"[{datetime.now().isoformat().replace('T', ' ')}] -> processing IE index.dat files..."
                        job.log.append(line)
                        job_storage.save_job(job)
                    continue  # Skip individual IE index.dat entries

                # Only include lines with ' -> ' (audit log format) OR phase messages OR errors/tracebacks
                # When debug is enabled, show ALL lines
                if not debug_enabled:
                    has_arrow = " -> " in line
                    is_phase_line = ("commencing" in line.lower() and "phase" in line.lower()) or \
                                    ("completed" in line.lower() and "phase" in line.lower())
                    # Also show Python tracebacks, errors, and DEBUG output
                    is_error_line = line.startswith("Traceback") or line.startswith("  File ") or \
                                   "Error:" in line or "Exception:" in line or \
                                   "DEBUG" in line or line.startswith("    ")  # Indented traceback lines
                    if not has_arrow and not is_phase_line and not is_error_line:
                        continue

                # Skip lines that are just separator dashes (e.g., "----------------------------------------")
                if re.match(r'^\[.*\]\s*-+\s*$', line) or re.match(r'^-+$', line.strip()):
                    continue

                # Skip redundant "X phase complete." messages (we show "Completed X Phase" instead)
                if re.search(r'(collect|process|analysis)\s+phase\s+complete\.?$', line, re.IGNORECASE):
                    continue

                # Clean up duplicate slashes in file paths (e.g., //$ -> /$)
                line = re.sub(r"/+", "/", line)

                # Fix timestamp format: convert "-> YYYY-MM-DD HH:MM:SS.ffffff -> message" to "[YYYY-MM-DD HH:MM:SS.ffffff] -> message"
                timestamp_pattern = (
                    r"^->\s+(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d+)\s+->\s+(.+)$"
                )
                timestamp_match = re.match(timestamp_pattern, line)
                if timestamp_match:
                    timestamp = timestamp_match.group(1)
                    message = timestamp_match.group(2)
                    line = f"[{timestamp}] -> {message}"

                # Format phase headers (Commencing/Completed) with visual separators BEFORE deduplication
                original_line = line
                is_phase_message = False
                phase_key = None  # Used for deduplicating phase messages
                if "commencing" in line.lower() and "phase" in line.lower():
                    # Extract the phase name (e.g., "Collection", "Processing", "Analysis")
                    phase_match = re.search(r"commencing\s+(.*?)\s*phase", line, re.IGNORECASE)
                    if phase_match:
                        phase_name = phase_match.group(1).strip().title()
                        # Simplify "Att&Ck速 Navigator" to just "Navigator"
                        phase_name = re.sub(r"Att&Ck速\s*", "", phase_name, flags=re.IGNORECASE)
                        phase_key = f"commencing_{phase_name.lower()}"
                        line = f"========== Commencing {phase_name} Phase =========="
                        is_phase_message = True
                        # Track analysis phase start
                        if "analysis" in phase_name.lower():
                            analysis_phase_started = True
                elif "completed" in line.lower() and "phase" in line.lower():
                    # Extract just the phase name, ignoring "for 'image'" suffixes
                    # Match: "Completed X Phase" or "Completed X Phase for 'image'"
                    phase_match = re.search(r"completed\s+(.*?)\s*phase", line, re.IGNORECASE)
                    if phase_match:
                        phase_name = phase_match.group(1).strip().title()
                        # Simplify "Att&Ck速 Navigator" to just "Navigator"
                        phase_name = re.sub(r"Att&Ck速\s*", "", phase_name, flags=re.IGNORECASE)

                        # Check if this is a per-image completion ("for 'image'") or overall completion
                        # Per-image completions should NOT be formatted as major phase transitions
                        is_per_image = " for " in line.lower() or "for '" in line.lower()

                        if is_per_image:
                            # Per-image completion - don't format as major phase transition
                            # Just skip these entirely since they're redundant with overall phase completion
                            continue
                        else:
                            # Overall phase completion - format as major separator
                            phase_key = f"completed_{phase_name.lower()}"
                            line = f"========== Completed {phase_name} Phase =========="
                            is_phase_message = True
                            # Track phase completions for validation
                            phase_name_lower = phase_name.lower()
                            if "collection" in phase_name_lower:
                                phases_completed["collection"] = True
                            elif "processing" in phase_name_lower:
                                phases_completed["processing"] = True
                            elif "analysis" in phase_name_lower:
                                phases_completed["analysis"] = True

                # Deduplicate phase messages: only show each phase transition once
                if is_phase_message and phase_key:
                    if phase_key in seen_phases:
                        continue  # Skip duplicate phase message
                    seen_phases.add(phase_key)

                # Deduplicate: Skip if this exact action+filepath was already logged
                # Normalize message for comparison (remove extra quotes and whitespace)
                normalized_current = re.sub(r"'{2,}", "'", original_line).strip()

                # Extract action and filepath from the message for deduplication
                # Different actions (collecting, processing, analysing) on the same file should all be shown
                action = "unknown"
                action_match = re.search(r"->\s*(collecting|processing|analysing|scanning|tagging|extracting)", normalized_current, re.IGNORECASE)
                if action_match:
                    action = action_match.group(1).lower()

                # Matches patterns like: '/path/to/file.ext' or "/path/to/file.ext" or 'filename'
                filepath_match = re.search(r"['\"]([^'\"]+)['\"]", normalized_current)
                # Only deduplicate if BOTH action and filepath are found
                # Messages without a clear filepath should always be shown
                if filepath_match and action != "unknown":
                    filepath = filepath_match.group(1).lower()
                    dedup_key = f"{action}:{filepath}"
                    if dedup_key in seen_filepaths:
                        continue  # Skip duplicate action+filepath message
                    seen_filepaths.add(dedup_key)

                last_log_message = original_line

                # Fix double single quotes (e.g., ''image_name'' -> 'image_name')
                line = re.sub(r"'{2,}", "'", line)

                # Add IE index.dat summary BEFORE the "Completed Processing Phase" message
                # Check original_line to detect phase completion, add summary before appending the phase line
                if "completed processing phase" in original_line.lower() and " for " not in original_line.lower():
                    if ie_indexdat_count > 0:
                        job.log.append(
                            f"[{datetime.now().isoformat().replace('T', ' ')}] -> processed {ie_indexdat_count} IE index.dat files"
                        )

                # Update log - only add timestamp if line doesn't already have one
                # Check if line starts with a timestamp (YYYY-MM-DD format or contains ' -> ')
                if re.match(r"^\d{4}-\d{2}-\d{2}", line) or " -> " in line:
                    # Line already has timestamp, don't add another
                    job.log.append(line)
                else:
                    # No timestamp, add one
                    log_entry = f"[{datetime.now().isoformat().replace('T', ' ')}] {line}"
                    job.log.append(log_entry)

                # Update progress based on phase transitions (more accurate than counting)
                progress_count += 1
                line_lower = line.lower()
                # Use original_line for phase detection since 'line' may have been reformatted
                original_lower = original_line.lower()

                # Phase-based progress calculation
                # Rivendell phases: Identification (0-15%) -> Collection (15-35%) -> Processing (35-70%) -> Analysis (70-95%)
                new_progress = job.progress  # Start with current progress

                # Detect phase transitions
                # Note: Rivendell outputs "Completed X Phase for 'image'" for EACH image
                # We only want to advance major progress on OVERALL phase completion (no "for" suffix)
                # Use original_lower since the reformatting strips " for 'image'" from messages
                if "commencing identification phase" in original_lower and " for " not in original_lower:
                    current_phase = "identification"
                    new_progress = max(new_progress, 2)
                elif "commencing collection phase" in original_lower and " for " not in original_lower:
                    current_phase = "collection"
                    new_progress = max(new_progress, 15)
                elif "commencing processing phase" in original_lower and " for " not in original_lower:
                    current_phase = "processing"
                    new_progress = max(new_progress, 35)
                elif "commencing analysis phase" in original_lower and " for " not in original_lower:
                    current_phase = "analysis"
                    new_progress = max(new_progress, 70)
                # Only trigger phase completion for OVERALL completion (no "for 'image'" suffix)
                elif "completed identification phase" in original_lower and " for " not in original_lower:
                    new_progress = max(new_progress, 15)
                elif "completed collection phase" in original_lower and " for " not in original_lower:
                    new_progress = max(new_progress, 35)
                elif "completed processing phase" in original_lower and " for " not in original_lower:
                    new_progress = max(new_progress, 70)
                elif "completed analysis phase" in original_lower and " for " not in original_lower:
                    new_progress = max(new_progress, 95)
                elif any(keyword in original_lower for keyword in ["splunk phase", "elastic phase", "navigator phase"]):
                    new_progress = max(new_progress, 92)
                elif "rivendell completed" in original_lower or "analysis finished" in original_lower:
                    new_progress = 95

                # Sub-progress within each phase
                # Scale progress increments by number of images (more images = more work = slower increment per line)
                scale_factor = max(1, total_images)

                # Separate if-chain for sub-progress within phases
                if current_phase == "identification":
                    # Identification: 0-15%
                    if "scanning for forensic images" in line_lower:
                        new_progress = max(new_progress, 3)
                    elif "found forensic image" in line_lower:
                        new_progress = max(new_progress, 5)
                    elif "mounting" in line_lower:
                        # Scale mounting progress by number of images
                        new_progress = max(new_progress, 7 + min(progress_count // (5 * scale_factor), 5))
                    elif "identified platform" in line_lower:
                        new_progress = max(new_progress, 12 + min(progress_count // (10 * scale_factor), 3))
                    elif "not mounted" in line_lower:
                        pass  # Don't advance progress for failed mounts

                elif current_phase == "collection":
                    # Collection: 15-35% (20% range)
                    # Track per-image collection completion
                    if "collection completed for" in line_lower:
                        images_collected += 1
                        # Each image completion advances within collection phase
                        per_image_progress = min(18, 18 * images_collected // scale_factor)
                        new_progress = max(new_progress, 15 + per_image_progress)
                    elif "collecting artefacts for" in line_lower:
                        # Scale by number of images
                        new_progress = max(new_progress, 16 + min(progress_count // (50 * scale_factor), 15))
                    elif any(kw in line_lower for kw in ["collecting", "copying", "configuration file", "crontab", "bash", "plist", "keyring"]):
                        new_progress = max(new_progress, 17 + min(progress_count // (30 * scale_factor), 16))

                elif current_phase == "processing":
                    # Processing: 35-70% (35% range)
                    if "processing completed for" in line_lower:
                        images_processed += 1
                        per_image_progress = min(30, 30 * images_processed // scale_factor)
                        new_progress = max(new_progress, 35 + per_image_progress)
                    elif any(kw in line_lower for kw in ["processing", "parsing", "extracting"]):
                        new_progress = max(new_progress, 36 + min(progress_count // (20 * scale_factor), 30))

                elif current_phase == "analysis":
                    # Analysis: 70-95% (25% range)
                    if any(kw in line_lower for kw in ["analyzing", "scanning", "tagging"]):
                        new_progress = max(new_progress, 71 + min(progress_count // (15 * scale_factor), 20))

                # Only update if progress increases (never go backwards)
                job.progress = max(job.progress, min(new_progress, 95))

                # Save periodically (every 10 lines)
                if progress_count % 10 == 0:
                    job_storage.save_job(job)

                logger.info(line)

        # Wait for completion
        return_code = process.wait()

        # Close verbose log file if it was opened
        if verbose_log_file:
            try:
                verbose_log_file.close()
                logger.info("Verbose log file closed")
            except Exception as e:
                logger.warning(f"Failed to close verbose log file: {e}")

        # Validate that required phases completed
        # If analysis was requested (started), it must also complete
        analysis_requested = getattr(job.options, "analysis", False)
        phases_ok = True
        incomplete_reason = None

        # Check if analysis was started but not completed
        if analysis_phase_started and not phases_completed["analysis"]:
            phases_ok = False
            incomplete_reason = "Analysis phase started but did not complete"
        # If analysis was explicitly requested but never even started
        elif analysis_requested and not analysis_phase_started:
            phases_ok = False
            incomplete_reason = "Analysis was requested but phase never started"

        if return_code == 0 and phases_ok:
            # Success - process completed AND all phases finished
            job.status = JobStatus.COMPLETED
            job.progress = 100

            job.log.append(
                f"[{datetime.now().isoformat().replace('T', ' ')}] -> rivendell completed successfully"
            )
        elif return_code == 0 and not phases_ok:
            # Process exited cleanly but required phases didn't complete - this is a FAILURE
            job.status = JobStatus.FAILED
            job.error = incomplete_reason
            job.log.append(
                f"[{datetime.now().isoformat().replace('T', ' ')}] -> Analysis incomplete: {incomplete_reason}"
            )
            # Log which phases were seen
            completed_phases = [k for k, v in phases_completed.items() if v]
            if completed_phases:
                job.log.append(
                    f"[{datetime.now().isoformat().replace('T', ' ')}] -> Completed phases: {', '.join(completed_phases)}"
                )
            else:
                job.log.append(
                    f"[{datetime.now().isoformat().replace('T', ' ')}] -> No phases completed successfully"
                )

        # Collect results information for success/incomplete cases
        if return_code == 0:
            result_info = {
                "output_directory": dest_dir_str,
                "return_code": return_code,
                "analysis_duration": str(datetime.now() - job.started_at),
                "phases_completed": phases_completed,
            }

            # Check for generated files
            output_path = dest_dir
            if output_path.exists():
                try:
                    # Skip macOS resource fork files (._*) which can cause permission errors
                    all_files = [f for f in output_path.rglob("*") if not f.name.startswith('._')]
                    result_info["output_files"] = len(all_files)
                    result_info["output_size"] = sum(
                        f.stat().st_size for f in all_files if f.is_file()
                    )
                except (FileNotFoundError, PermissionError, OSError) as e:
                    # Handle cases where paths don't exist or are inaccessible
                    logger.warning(f"Error calculating output stats: {e}")
                    result_info["output_files"] = 0
                    result_info["output_size"] = 0

            job.result = result_info

            # Save template if requested
            if getattr(job.options, "save_template", False):
                try:
                    template_data = {}
                    # Extract all processing options (exclude mode selections and save_template itself)
                    mode_keys = {'brisk', 'exhaustive', 'custom', 'template', 'save_template', 'collect', 'process'}
                    for key, value in vars(job.options).items():
                        if not key.startswith('_') and key not in mode_keys and isinstance(value, bool):
                            template_data[key] = value

                    # Generate filename with timestamp
                    timestamp = datetime.now().strftime("%Y-%m-%d-%H:%M")
                    template_filename = f"{timestamp}_Template.json"
                    template_path = dest_dir / template_filename

                    with open(template_path, "w") as f:
                        json.dump(template_data, f, indent=2)

                    job.log.append(
                        f"[{datetime.now().isoformat().replace('T', ' ')}] -> Template saved: {template_filename}"
                    )
                except Exception as e:
                    logger.warning(f"Failed to save template: {e}")
                    job.log.append(
                        f"[{datetime.now().isoformat().replace('T', ' ')}] -> Warning: Failed to save template: {e}"
                    )

        if return_code != 0:
            # Failed
            job.status = JobStatus.FAILED
            job.error = f"Process exited with code {return_code}"
            job.log.append(f"[{datetime.now().isoformat().replace('T', ' ')}] -> Analysis failed: {job.error}")

    except Exception as e:
        logger.exception(f"Error running analysis for job {job_id}")
        job.status = JobStatus.FAILED
        job.error = str(e)
        job.log.append(f"[{datetime.now().isoformat().replace('T', ' ')}] -> Error: {str(e)}")

    finally:
        # Release image locks
        if acquired_lock_keys:
            release_image_locks(acquired_lock_keys)
            logger.info(f"Job {job_id}: Released {len(acquired_lock_keys)} image lock(s)")

        job.completed_at = datetime.now()
        job_storage.save_job(job)


def build_elrond_command(job):
    """
    Build elrond command from job options.

    Args:
        job: Job object

    Returns:
        Command list for subprocess
    """
    cmd = []

    # Case number
    cmd.append(job.case_number)

    # Source paths (translate from backend to worker perspective)
    translated_sources = [translate_path_for_worker(p) for p in job.source_paths]
    cmd.extend(translated_sources)

    # Destination path (mirror job creation logic and translate to worker perspective)
    dest_path = str(_resolve_destination(job))
    translated_dest = translate_path_for_worker(dest_path)
    cmd.append(translated_dest)

    opts = job.options

    # Primary mode flags
    # Process is ALWAYS invoked
    cmd.append("--Process")

    # Note: elrond.py already runs in auto mode by default (auto = True)
    # No --Auto flag needed

    # Collection mode (mutually exclusive)
    if opts.gandalf:
        # Gandalf mode: process pre-collected artifacts (no collection)
        cmd.append("--Gandalf")
    else:
        # Default/Local mode: collect from disk image
        cmd.append("--Collect")

    # Analysis options
    analysis_requested = getattr(opts, "analysis", False)
    magic_bytes_requested = analysis_requested or getattr(opts, "magic_bytes", False)

    if analysis_requested:
        cmd.append("--Analysis")
    if magic_bytes_requested:
        cmd.append("--magicBytes")
    if opts.extract_iocs:
        cmd.append("--extractIocs")
    if opts.iocs_file:
        cmd.extend(["--iocsFile", opts.iocs_file])
    if opts.misplaced_binaries:
        cmd.append("--misplacedBinaries")
    if opts.masquerading:
        cmd.append("--masquerading")
    if opts.keywords_file:
        cmd.extend(["--Keywords", opts.keywords_file])
    if opts.yara_dir:
        cmd.extend(["--Yara", opts.yara_dir])

    # Collection options
    # Build file selection string for elrond (matches select.py file_selection letters)
    # A=All, H=Hidden, B=Binaries, D=Documents, R=Archives, S=Scripts,
    # L=LNK, W=Web, M=Mail, V=Virtual, U=Unallocated
    file_selection = ""

    if opts.collect_files_all:
        file_selection = "A"  # All includes everything + carving
    else:
        if opts.collect_files_hidden:
            file_selection += "H"
        if opts.collect_files_bin:
            file_selection += "B"
        if opts.collect_files_docs:
            file_selection += "D"
        if opts.collect_files_archive:
            file_selection += "R"
        if opts.collect_files_scripts:
            file_selection += "S"
        if opts.collect_files_lnk:
            file_selection += "L"
        if opts.collect_files_web:
            file_selection += "W"
        if opts.collect_files_mail:
            file_selection += "M"
        if opts.collect_files_virtual:
            file_selection += "V"
        if opts.collect_files_unalloc:
            file_selection += "U"  # Unallocated = carving only

    if file_selection:
        # Pass file selection to elrond via --collectFiles with selection string
        cmd.extend(["--collectFiles", file_selection])
    elif opts.collectFiles:
        if opts.collectFiles_filter:
            cmd.extend(["--collectFiles", opts.collectFiles_filter])
        else:
            cmd.append("--collectFiles")

    if opts.vss:
        cmd.append("--vss")
    if opts.userprofiles:
        cmd.append("--Userprofiles")

    # Processing options
    if opts.timeline:
        cmd.append("--Timeline")
    if opts.memory:
        cmd.append("--Memory")
    if opts.memory_timeline:
        cmd.append("--memorytimeline")

    # Output options
    if opts.splunk:
        cmd.append("--Splunk")
    if opts.elastic:
        cmd.append("--Elastic")
    if opts.navigator:
        cmd.append("--Navigator")

    # Speed/Quality modes
    if opts.brisk:
        cmd.append("--Brisk")
    if opts.mordor:
        cmd.append("--Mordor")

    # Hash comparison
    if opts.nsrl:
        cmd.append("--nsrl")
    if opts.hash_collected:
        cmd.append("--hashCollected")

    # Post-processing
    if opts.delete:
        cmd.append("--Delete")
    if opts.archive:
        cmd.append("--Ziparchive")

    return cmd
